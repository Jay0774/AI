ASSIGNMENT 1 - REPORT

Team Members:

1) Abhijit S Iyer - M21CS001
2) Jayesh Budhwani - M21CS007

Search strategy used:

Used Local Search technique by creating a new state from an existing state by swapping papers between sessions and checking if the goodness value generated by the new session has a greater value than the older session we tried.

We then figure out the maximum goodness by picking the state with highest goodness out of all the states explored.

Description of algorithm:

In the defined algorithm we are creating a new state by randomly swapping the papers between different sessions. As the papers are swapped the goodness is changed to calculate the new goodness. We calculate the similarity between the sessions of newly created states, similarly we calculate the distance of the newly created state sessions.

After calculating the new Similarities and distance we subtract the original and add the new parameters to calculate the new goodness.
Finally if the new goodness is greater than the original/previous we change our solution to the new state.
As we know there will be n! ways possible to create a new state, but that is not possible so by inducing the randomness in a solution we can reach the goal state easily and quickly.

General Algorithm defined:
1. Input : k, p, t, distance and similarity
2. Initialize : arr variable as 0 to n-1 and n = t*p*k (Total number of papers)
3. Calculate the goodness of arr.
4. Def loacl_search()
5.  Run iterations
6.		new_arr,goodness_new = create_new_state(arr)
7.		if goodness_new>goodness then
8. 			arr = new_arr
9.			goodness = new_goodness
10. final_arr = local_search(arr)			
11. print_schedule(final_arr)

Heuristic Used:

We are using the history of calculated goodness values as a heuristic, to check if we have arrived at an optimal solution by comparing the historical heuristic value with the present heuristic value. 

Note:

1. We tried using a different heuristic like using the distances to find the most compatible papers that can run in the session by using the large values distances and finding their intersection but it does not reach the goal state.

2. We also tried the backtracking method of arriving at the desired goal state by moving back to earlier states created and adjusting papers. However, this solution took a lot of execution time, hence we did not proceed further with this.

